---
layout: page
title:  "Hacker News (HN) - Part 1: analysis"
date:   2024-04-02 00:00:00 +0200
published: true
tags: strategy planning
image: /assets/images/hn_part_1/author_cum_score_vs_median_score_logscale_lucky.png
---

<!-- # Hacker News (HN) - Part 1: analysis -->

What is the status of the ~18 year-old HN?

Instead of reading the stories, why not just dismantle HN and look under the hood?

I love HN, and it has these beautiful APIs that can exposes most of HN data, so I went for it. I extracted ~40M items, plus ~0.5 M users (who shared stories). This is the second large data harvesting project I do after LeMonde ([1](https://blog.osm-ai.net/data-science/machine-learning/nlp/2022/02/15/french-journey-part-1.html), [2](https://blog.osm-ai.net/data-science/machine-learning/nlp/2022/08/18/french-journey-part-2.html), [3](https://blog.osm-ai.net/thinking/2023/09/23/french-journey-part-3.html)).

[The code for this work can be found here](https://github.com/osm3000/hackernews_ml).

There are 3 key takeaways from this work:

1. It seems that HN is losing more contributors (users who comment or share stories) than it is earning new ones.
    1. It might be time to consider a new interface / user experience.
2. If HN is a game, and user‚Äôs karma is the score, then the best strategy to win this game is via consistency in sharing stories. Targeting flashy news or relying on luck will not get you far enough.
3. While software development and business are traditionally the dominant topics, they were overtaken by AI in 2023, while the discussion about business is steadily declining.

**NOTE**: Please take into account that I don‚Äôt know the actual objectives of HN (E.g., I saw many debates about HN not being reddit‚Ä¶don‚Äôt know, and don‚Äôt care). You can imagine this analysis as if HN is just another SaaS product.

# HN general stats

HN is composed of 5 item types. The majority lies in the comment and story items. 

| Type | Frequency | Percentage |
| --- | --- | --- |
| Comment | 34.3 M | 86.8 |
| Story | 5.2 M | 13.12 |
| Job | 16.7 K | 0.04 |
| Pollopt | 14.7 K | 0.04 |
| Poll | 2 K | 0.01 |

Since the beginning of HN, there was a steady growth in the number of shared stories, up until 2011. After that, this number plateaus. 

![freq_of_story_per_year.png](/assets/images/hn_part_1/freq_of_story_per_year.png)

Comments, on the other hand, is still growing, albeit at a shrinking pace in the last 3 years (visual observation).

![freq_of_comment_per_year.png](/assets/images/hn_part_1/freq_of_comment_per_year.png)

## Characteristic of contributers

When we look at the users who share stories, we can see that, on average, the users who started sharing stories, stop doing that after 1 year (see a comment about this analysis at the end).

![active_years_histogram.png](/assets/images/hn_part_1/active_years_histogram.png)

When we look at the first and last appearance of those users, we can see that those curves almost follow each other. This can be a proxy for user churn rate. We can see that the number of users stopped sharing has surpassed those who share starting from ~2020 and afterwords.

![new_and_last_users_per_year.png](/assets/images/hn_part_1/new_and_last_users_per_year.png)

But is this related to users who share stories only? What about those who share comments?

Interestingly, we can see similar character**i**stics between both types of contributors.

![commentators_active_years_histogram.png](/assets/images/hn_part_1/commentators_active_years_histogram.png)

![commentators_new_and_last_users_per_year.png](/assets/images/hn_part_1/commentators_new_and_last_users_per_year.png)

*All of this indicate to me that HN is losing more contributors than it earns news ones, and that this trend started ~3 years ago. Some hypotheses (not orthogonal) might be:*

1. *Maybe HN have reached its maximum potential that its design can afford.* 
2. *Or users are turning away from HN, perhaps in favor of other platforms.*
3. *The age of HN users is getting older, and new users are not attracted to it: [this is similar to what Facebook is experiencing](https://www.theverge.com/22743744/facebook-teen-usage-decline-frances-haugen-leaks).*

Would love to hear your thoughts regarding this issue.

# Upvoting stories & user‚Äôs score (~karma)

For those who are not familiar with HN, here is a summary of relevant concepts:

1. Each user has a profile. There is a score, ‚Äúkarma‚Äù, in the user‚Äôs profile, which kind of signify this user‚Äôs reputation. This is visible to everyone.
2. Users can share stories, write comments.
3. Other users can upvote these stories / comments.
4. The total upvotes for the stories are visible to everyone, which is not the case for the comments.
    1. *Update*: apparently after a certain karma, the user can downvote / flag stories and comments.

While the intention of HN is not the score (I hope), I am interested in understanding this aspect. Specifically: How can a user maximize their score? Is it by sharing high-impact stories? Or by consistently sharing stories?

First, I will model these concepts the following:

1. Targeting high-impact : I will assume that the median upvotes of stories shared be a user will be a suitable metric.
    1. I get the deceptive nature of this metric. High-impact is from the user perspective, and the median upvotes is from the reader‚Äôs perspective. For now, I will assume that both are the same.
2. Consistency: This will be the total number of stories shared by the user.
3. User‚Äôs score: While naturally it should be the user‚Äôs karma, I found several inconsistencies in the HN data (I will discuss this later). For now, I decided to use a different metric: the user‚Äôs cumulative upvotes (which is the sum of the upvotes that the stories shared by a user earned).

Let‚Äôs first look at the relationship between the user‚Äôs cumulative upvotes and their consistency.

In the figure below, when looking at the number of stories shared by each user versus the cumulative upvotes that user has achieved, we can see that there is very high degree of correlation between both $$ R^{2}=0.78 $$. 

![nb_of_stories_vs_author_total_score.png](/assets/images/hn_part_1/nb_of_stories_vs_author_total_score.png)

This is interesting, since that big hits are not what drives the score of the top users. It is all about consistency in sharing stories. Just being there and keep doing that is what matters.

But what about targeting impact? Do successful users adopt this strategy? or is it a game of numbers for them (consistency)? Or there is something in between? (of course the previous high $$R^2$$ gives it away, but let‚Äôs play üòâ).

To explore that, I looked at the relationship between all these three variables in the graph below.

![author_cum_score_vs_median_score_logscale_lucky.png](/assets/images/hn_part_1/author_cum_score_vs_median_score_logscale_lucky.png)

We can observe:

1. In the first half of the graph (up until a score of ~1000)
    1. Users can focus on impact to increase their score.
    2. But the density of this trend gets less and less, the more you increase the score and focus on impact, suggesting that luck might have something to do with it (e.g., you are the first person to share the news of the death of a celebrity).
    3. There seems to be a limit after which this strategy doesn‚Äôt work anymore, thus leading us to‚Ä¶
2. ‚Ä¶the second half of the graph (from the score of 1000)
    1. Higher scores (and ultimately the top scores) can mainly be achieved by focusing on the number of shared stories.

This wall, while visually appealing, can be misleading (as with all ‚Äúvisual evidence‚Äù). So I tried to quantify this a little bit further.

I divided each of those dimensions into 3 categories: low, medium and high. And then I just counted the frequencies in the table below, and normalized them by column.

![The choice of the bins, for each dimension, was based on the same log jumps: 0, 100, 10K, inf](/assets/images/hn_part_1/Screenshot_2024-04-02_at_08.55.40.png)

The choice of the bins, for each dimension, was based on the same log jumps: 0, 100, 10K, inf

In the last column, related to high scores, we can see that the vast majority of the high score has been achieved with medium-to-high number of stories, mainly on low impact.

*So, if you want to want to win the HN game, consistency in sharing is the winning strategy.*

# Topics trend

Finally, I wanted to take a look at the trends of the topics over the years, based on the title of the stories. For visualization sake, I focused on the top 10 topics (the figure below).

![hackernews_topic_percentage.png](/assets/images/hn_part_1/hackernews_topic_percentage.png)

We can see, as expected, the business is one of the most dominant topic of discussions since the beginning. The same goes for software development. But then over the years, the business topics seems to be declining, while the ai and machine learning are skyrocketing, overtaking the top 2 trends in 2023.

## Personal note: Why am I doing this?

These kind of projects challenge my technical skills: setting up DBs, infrastructure, monitoring, analytics, recovery points, scaling. At this scale, mistakes are expensive, and suboptimal decisions will be a PITA or slow things down greatly (Will probably discuss this in another post). 

I like working on dynamic data: I can just go there and fetch the latest, thus allowing a opening the door for more interesting projects, like predicting trends of the shared stories. Static data dumped on Kaggle can be extremely boring.

I am considering building a new interface for me on top of HN. There is mainly one way to view HN stories at the moment, via the board. Why not build a personalized recommendation system on top of that to send me selected stories that I am interested in? Or build an interface to follow certain users and the stories they share? I feel HN is far from its maximum potential.

While doing this, I ended up looking at a lot of old news, looking at things from a very different perspective. Examples:

1. The top performer until ~2015 in HackerNews is [ColinWright](https://news.ycombinator.com/user?id=ColinWright). Why do I know this info? Because I started analyzing the data while the extraction process was still running, and at that time, I had the data only from 2006 until 2015. One of the posts he shared was an analysis on the [HackerNews dynamics](http://www.solipsys.co.uk/new/TrackingAnItemOnHackerNews.html?HN_20150505), and thus to his website. I loved it! Almost no CSS, pure and simple HTML, yet beautiful and elegant.
2. I went though unexpected old posts that did touch me:
    1. [The death of Aaron Swartz](https://news.ycombinator.com/item?id=5046845): I knew very little about Aaron when he was alive, and only few years ago I came to know more about him when I watched ‚Äú[The internet‚Äôs own boy](https://en.wikipedia.org/wiki/The_Internet%27s_Own_Boy)‚Äù documentary about him. His story still resonates me, as I became more and more confident that there no justice in this world, and that the law is nothing more of a tool for a few to keep the leash on the rest and maintain the status-quo.
    One of this blog posts, ‚Äú[What happens to the Dark Knight](https://news.ycombinator.com/item?id=5047421)‚Äù, still gives me a lot to think about.
    Another person made a [list of Aaron‚Äôs work](https://news.ycombinator.com/item?id=5047325) to honor him. One of it was the `[webpy](https://github.com/webpy/webpy)` python web framework, which was a nice discovery. I always wanted to learn what a web framework looks like under the hood. Flask or - god forbid - Django source code is much more complicated, but webpy seems more feasible and approachable to learn. 
    2. [A UX designer who learned how to build a web app using Python-Django back in 2011](https://news.ycombinator.com/item?id=2227770)
        1. Her website had a story about her personal business, and even though it was profitable, she decided shut it down, and estimating the cost of the lost opportunity. This had a deep effect on me, as I am considering going through this journey myself.
    3. By a coincidence, while looking at the data, I found that the [story with `id=21` is made by `sama`](https://news.ycombinator.com/item?id=21) . I only know one `sama`, Sam Altman (OpenAI), which indeed turned out to be his account (apparently he is not active since ~3 years now). On the post, there is a comment from `pg` , which turned out to be Paul Graham.
    These are not earth shattering discoveries, probably irrelevant to anyone. But I love how looking at the data from a different point of view yielded such info.

A different perspective opens the door for wonderful discoveries.

# Notes on the analysis

## Why I didn‚Äôt use the user‚Äôs karma?

I found multiple weird patterns in the user‚Äôs karma. For example, some users, who shared stories with large number of upvotes, had zero karma. Even more interestingly, there was negative karma. I don‚Äôt even know how this came to be.

| Karma level | Percentage |
| --- | --- |
| Positive | ~97.9 % |
| Zero | ~1 % |
| Negative | ~1.13 % |

Then, there are people who shared stories, with a median of more than one, yet, their karma is one (See the table below: Percentages, normalized by index)

|  | Karma < 0 | Karma > 0 | Karma == 0 |
| --- | --- | --- | --- |
| Median < 5 | 1.21 | 97.72 | 1.07 |
| 5 < Median < 10 | 0.56 | 99 | 0.42 |
| Median > 10 | 0.24 | 99.66 | 0.10 |

I know what you might be thinking: these are low percentage of outliers. But this is what I found visually (the tables are just to communicate the observation). 

It is very possible that this metric is tied to something else, like the upvotes on the user‚Äôs comments (this data is not available), or comments on their shared stories, or followups on the user‚Äôs comments.

All of this left me unsure about what the meaning of karma is exactly.

***Update***: This [Wikipedia article](https://en.wikipedia.org/wiki/Hacker_News) clarified a bit more the dynamics of the karma.

> However, unlike Reddit where new users can immediately both upvote and 
downvote content, Hacker News does not allow users to downvote content 
until they have accumulated 501 "karma" points. Karma points are 
calculated as the number of upvotes a given user's content has received 
minus the number of downvotes.[[2]](https://en.wikipedia.org/wiki/Hacker_News#cite_note-tc-evol-2) "Flagging" comments, likewise, is not permitted until a user has 30 karma points.
> 

This might explain things. Although I have a 30 karma points and I can‚Äôt flag comments, thus, suggesting there was a change to this system.

## When calculating the user expected lifetime

When I made this analysis, I only took the ‚Äúyear‚Äù part of the first / last appearance dates for the users, to simplify my life. This means that:

1. A user whose first appearance is 31/12/2011 and his last appearance is 01/01/2012 will be counted as active for a year
2. A user whose first appearance is 01/01/2011 and his last appearance is 31/12/2011 will be counted as active for a year only as well.
3. So, the true number here (of the expected user lifetime) is between 0~2 years.

## User‚Äôs trend graph

I‚Äôve also excluded the users who just appear in 2023, 2024, or last seen in 2024, as the year is far from over, and those it is not possible to make conclusions about it.

## Topic modeling

I went all over the place with this one.

Recently [I saw this post](https://news.ycombinator.com/item?id=39852219), where the authors analysis the topics of OpenAI forums using [Atlas Nomic](http://atlas.nomic.ai). It looked impressive. But when I tried it myself [(results here)](https://atlas.nomic.ai/data/omarsamir3000/lumbering-boltzmann/map), I really didn‚Äôt like the extracted topics. It is always an issue for me with these unsupervised, generic techniques.

Then I followed a semi-traditional approach: In order to that, I made an initial list of the topics that I thought were relevant, annotated some date accordingly, reviewed the topics list, more annotation,‚Ä¶etc. That went back and forth many times until I settled on a list of topics that seemed satisfying enough. 
Afterwords, I relied on GPT-4 to get the topics for each of the story titles. Few rounds of cleaning afterwords, and that was the final outcome

There are limitations of this work though:

1. The actual quality of the annotated topics is questionable. After all, what is the criteria of quality in this case?
2. I decided on a single topic per story title. This is a major simplification.
3. Relying on the story title to extract the topic is limiting, since it is just a sentence at best. 

# Acknowledgement

Many thanks to [Tamara Persikova](https://www.linkedin.com/in/tamarapersikova/) and [Anya Ruvinskaya](https://www.linkedin.com/in/anya-ruvinskaya/) for reviewing this work. Based on their comments, I rewrote most of this article around a more coherent structure (the draft I sent them was horrible üòÖ ).